{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importando bibliotecas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Função para eliminar valores NANS, transformar valores qualitativos em quantitativos e separar features e labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tratar_separar_dados(df):\n",
    "    \"\"\"  \n",
    "   Input:\n",
    "       df: pandas DataFrame com dados importados\n",
    "   Output:\n",
    "       dados_x: pandas DataFrame com dados do X (features) \n",
    "       dados_y: pandas DataFrame com dados do Y (label)\n",
    "   \"\"\"\n",
    "    ###Prencher os valores NANs\n",
    "    df = df.fillna(method='ffill')\n",
    "        \n",
    "    ######Transformar a coluna SEX em quantitativo\n",
    "    df.loc[(df['sex'] == 'M',\"sex\")] = 1\n",
    "    df.loc[(df['sex'] == 'm',\"sex\")] = 1\n",
    "    \n",
    "    df.loc[(df['sex'] == 'F',\"sex\")] = 0\n",
    "    df.loc[(df['sex'] == 'f',\"sex\")] = 0\n",
    "    \n",
    "    df['sex'] = df['sex'].astype(int)\n",
    "    ######\n",
    "    \n",
    "    ##plotar gráfico para ver correlação das features com o label\n",
    "    #sns.heatmap(df.corr(), annot=True)\n",
    "    \n",
    "    ###Obtendo dados do y (label)\n",
    "    dados_y = df['sex']\n",
    "    ###obtendo dados do x (features)\n",
    "    dados_x = df.drop(['sex'],axis=1)\n",
    "    \n",
    "    return dados_x, dados_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Essa função tem como objetivo normalizar os dados das features(x)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_dados (dados_x):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        dados_x: pandas Dataframe desnormalizado do x\n",
    "    Output: \n",
    "        dados_x_normalizado: array com dados do x normalizados\n",
    "    \"\"\"\n",
    "    ##Normalização dos dados do x\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(dados_x)\n",
    "    dados_x_normalizado = scaler.transform(dados_x)\n",
    "    \n",
    "    ##Salvando o scaler utilizado nos dados de treinamento\n",
    "    scaler_filename = \"scaler.save\"\n",
    "    joblib.dump(scaler, scaler_filename) \n",
    "    ###\n",
    "    \n",
    "    return dados_x_normalizado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Função para separar dados de treinamento e teste**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separar_dados_treinamento_teste(dados_x_norm, dados_y ,porcentagem):\n",
    "    \"\"\"\n",
    "   Input:\n",
    "       dados_x_norm: pandas DataFrame com dados de treinamento (x) normalizados\n",
    "       dados_y: pandas DataFrame com dados de treinamento(y)\n",
    "       porcentagem: inteiro com a porcetagem de dados de treinamento\n",
    "\n",
    "   Output:\n",
    "       dados_treinamento_x: array com dados do X de treinamento \n",
    "       dados_teste_x: array com dados do X de teste \n",
    "       dados_treinamento_y: array com dados do y de treinamento \n",
    "       dados_teste_y: array com dados do y de teste\n",
    "    \"\"\"\n",
    "    ##Obtendo o tamanho do dataframe importado\n",
    "    tamanho_df = len(dados_x_norm)\n",
    "    ##Obtendo quantidade de amostras que equivalem ao argumento porcentagem setado\n",
    "    porcentagem_treinamento = int((tamanho_df*porcentagem)/100)\n",
    "    ##Obtendo os valores de treinamento e teste do X\n",
    "    dados_treinamento_x = dados_x_norm.iloc[0:porcentagem_treinamento]\n",
    "    dados_teste_x = dados_x_norm.iloc[porcentagem_treinamento:tamanho_df]\n",
    "    ##Obtendo os valores de treinamento e teste do Y\n",
    "    dados_treinamento_y = dados_y.iloc[0:porcentagem_treinamento]\n",
    "    dados_teste_y = dados_y.iloc[porcentagem_treinamento:tamanho_df]\n",
    "   \n",
    "    return dados_treinamento_x, dados_teste_x, dados_treinamento_y, dados_teste_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Essa função tem objetivo diminuir a dimensionalidade dos dados.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diminuir_dimensionalidade(dados_x_norm):\n",
    "    \"\"\"\n",
    "   Input:\n",
    "       dados_x_norm: pandas DataFrame com dados importados e normalizados do X\n",
    "   Output:\n",
    "       x_pca: pandas DataFrame do dataFrame do X com dimensões reduzidas\n",
    "  \"\"\" \n",
    "    ##Aplicação do método PCA nos dados do x\n",
    "    pca = PCA(n_components=14)\n",
    "    pca.fit(dados_x_norm)\n",
    "    x_pca = pd.DataFrame(pca.transform(dados_x_norm))\n",
    "    ###\n",
    "    \n",
    "    return x_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Essa função tem como objetivo de encontrar os melhores parâmetros para o modelo do Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encontrar_melhores_parametros(x_train,y_train):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        x_train: lista com os valores de x (features)\n",
    "        y_train: lista com os valores de y (label)\n",
    "    Output: \n",
    "\n",
    "    \"\"\"\n",
    "    ##Criação de uma random forest\n",
    "    rfc=RandomForestClassifier(random_state=42)\n",
    "\n",
    "    ##Definição do espaço de busca\n",
    "    param_grid = { \n",
    "        'n_estimators': [50, 200],\n",
    "        'max_features': ['auto', 'sqrt', 'log2'],\n",
    "        'max_depth' : [2,4,5,6,7,8,10],\n",
    "        'random_state' :[0,10]\n",
    "    }\n",
    "    \n",
    "    CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "    CV_rfc.fit(x_train, y_train)\n",
    "    \n",
    "    print(CV_rfc.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Essa função tem como objetivo balancear a quantidade de amostras das classes (labels)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanceamento_das_amostras(x_train,y_train):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        x_train: lista com os valores de x (features)\n",
    "        y_train: lista com os valores de y (label)\n",
    "    Output: \n",
    "\n",
    "    \"\"\"\n",
    "    oversample = SMOTE()\n",
    "    x_bal, y_bal = oversample.fit_resample(x_train, y_train)\n",
    "    \n",
    "    y_bal = pd.DataFrame(y_bal,columns=['class'])\n",
    "    print(sum(y_bal['class'] == 0))\n",
    "    print(sum(y_bal['class'] == 1))\n",
    "\n",
    "    return x_bal,y_bal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Essa função tem como objetivo treinar modelos com os dados importados e devidamente tratados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar_modelo(x_train,y_train):\n",
    "    \"\"\"\n",
    "    Input: \n",
    "        x_train: lista de valores de treinamneto do x (features)\n",
    "        y_train: lista de valores de treinamento do y (label)\n",
    "    Output: \n",
    "        Pickle: modelo treinado\n",
    "    \"\"\"\n",
    "    ##Modelo MLPClassifier \n",
    "    #clf = MLPClassifier(random_state=10,hidden_layer_sizes=(50),tol=0.000001, verbose=False, max_iter=1550,solver='adam').fit(x_train, y_train)\n",
    "    #clf.fit(x_train,y_train)\n",
    "    \n",
    "    ##Modelo Random Forest\n",
    "    random_forest = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=10)\n",
    "    random_forest.fit(x_train,y_train)\n",
    "    return random_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Função principal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8275862068965517\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    ##Ler os dados dos pacientes disponíveis no csv \n",
    "    df_importado = pd.read_csv('test_data_CANDIDATE.csv',header=0)\n",
    "    df_importado = df_importado.set_index(['index'])\n",
    "    \n",
    "    ##Transformando os valores qualitativos em quantitativos (sex), remoção de features, e separando as features e label.\n",
    "    dados_x, dados_y = tratar_separar_dados(df_importado)\n",
    "    \n",
    "    ##Normalizando os dados das features (x)\n",
    "    dados_x_norm = pd.DataFrame(normalizar_dados(dados_x))\n",
    "\n",
    "    ##Diminuindo a dimensionalidade do problema \n",
    "    #pca_x = diminuir_dimensionalidade(dados_x_normalizado)\n",
    "    \n",
    "    ##Separar dados de treinamento e teste para criação de modelo\n",
    "    train_x, test_x, train_y, test_y = separar_dados_treinamento_teste(dados_x_norm,dados_y,80)\n",
    "\n",
    "    ##Transformando dataFrames em listas\n",
    "    train_x = train_x.values.tolist()\n",
    "    train_y = train_y.to_list()\n",
    "    test_x = test_x.values.tolist()\n",
    "    test_y = test_y.to_list()\n",
    "    \n",
    "    ##Encontrar melhores parametros para o modelo\n",
    "    #encontrar_melhores_parametros(train_x, train_y)\n",
    "    \n",
    "    ##Balanceado as amostras\n",
    "    #x,y = balanceamento_das_amostras(train_x,train_y)\n",
    "        \n",
    "    ##Treinar modelo \n",
    "    modelo = treinar_modelo(train_x,train_y)\n",
    "\n",
    "    ##Avaliando a acurácia do modelo treinado\n",
    "    print(modelo.score(test_x,test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salvar modelo treinado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'modelo_treinado.sav'\n",
    "pickle.dump(modelo, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
